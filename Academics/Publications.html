<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f9;
            color: #333;
        }
        h1, h2 {
            color: #333;
        }
        h1 {
            text-align: center;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h2 {
            margin-top: 2em; /* Adds more space above h2 elements */
        }
        ul {
            list-style-type: disc; /* Use bullets for lists */
            padding-left: 20px; /* Indent the list items */
        }
        .home-button {
    display: inline-block;
    padding: 10px 20px;
    background-color: #333; /* Dark gray background */
    color: #fff; /* White text */
    text-decoration: none; /* Removes underline */
    font-weight: bold; /* Bold text */
    border: none; /* Removes border */
    border-radius: 5px; /* Rounded corners */
    margin-top: 20px; /* Adds some space above the button */
}

.home-button:hover {
    background-color: #444; /* Darker gray on hover */
    cursor: pointer; /* Changes cursor to pointer on hover */
}

    </style>
</head>
<body>
<h2> Automatic Dastgah Recognition Using Markov Models</h2>
<p>CMMR 2019 | Marseille</p>
<p>This work focuses on automatic Dastgah recognition of monophonic audio recordings of Iranian music using Markov Models. We present an automatic recognition system that models the sequence of intervals computed from quantized pitch data (estimated from audio) with Markov processes. Classification of an audio file is performed by finding the closest match between the Markov matrix of the file and the (template) matrices computed from the database for each Dastgah. Applying a leave-one-out evaluation strategy on a dataset comprised of 73 files, an accuracy of 0.986 has been observed for one of the four tested distance calculation methods.</p>
<p>Published in <a href="https://link.springer.com/book/10.1007/978-3-030-70210-6" target="_blank">Perception, Representations, Image, Sound, Music</a> ISBN: 978-3-030-70210-6</p>
<p><a href="https://drive.google.com/file/d/1YPjFcJAnTe_zOXo3BkBXAXuM7yq2SA-0/view" target="_blank">Download the paper</a></p>
<h2>Towards A Real-Time Implementation Of Analogique B</h2>
<p>Proceedings of the international Symposium Xenakis. La musique électroacoustique / Xenakis. The electroacoustic music (université Paris 8, May 2012).</p>
<p>This paper details a real-time digital audio implementation of Xenakis's Analogique B. Drawing on his descriptions and prior analysis of his compositional "mechanism" and GRM studio practices in 1958, my implementation in Max-Msp comprises two key programming tasks: (1) rendering the Markov chain process and (2) a real-time granular synthesis engine driven by it. This dual structure reflects the inherent challenge in granular synthesis: representing both grain event sequences and the control structure needed for extensive data management at the grain level. The discussion of my implementation addresses technical issues and proposes future developments to overcome the inherent predictability of Xenakis's closed, memoryless stochastic process.</p>
<p>Published in <a href="https://www.youscribe.com/catalogue/ebooks/art-musique-et-cinema/musique/iannis-xenakis-la-musique-electroacoustique-2629553" target="_blank">Iannis Xenakis, la musique électroacoustique</a> ISBN 10: 2343066965  ISBN 13: 9782343066967</p>
<p><a href="https://drive.google.com/file/d/1PzGQBV8d06mKnWHGQkkCw3iGsOZ8AmQX/view" target="_blank">Download the paper</a></p>
<p><a href="https://drive.google.com/file/d/1lpmwLmlveYOHW-aVWdQYG9YaDmKsEXTF/view" target="_blank">Audio Example</a></p>
<h2>Environment like strings</h2>
<p>International Symposium - musique et ècologie du son (université Paris 8, May 2013)</p>
<p>a sophisticated algorithm for my augmented instrument called FeedGuitar that take into account the history of the musical performance signal and the performer's gestures</p>
<p><a href="https://drive.google.com/file/d/1x0qeM3pKJiHCCKJ2CvCbJWmF4Toto-ze/view" target="_blank">Download the poster</a></p>

<p><a href="https://luciamarock.github.io/" class="home-button">Back to Home</a></p>
</body>
</html>
