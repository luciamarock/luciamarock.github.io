<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f9;
            color: #333;
        }
        h1, h2 {
            color: #333;
        }
        h1 {
            text-align: center;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        h2 {
            margin-top: 2em; /* Adds more space above h2 elements */
        }
        ul {
            list-style-type: disc; /* Use bullets for lists */
            padding-left: 20px; /* Indent the list items */
        }
        .home-button {
    display: inline-block;
    padding: 10px 20px;
    background-color: #333; /* Dark gray background */
    color: #fff; /* White text */
    text-decoration: none; /* Removes underline */
    font-weight: bold; /* Bold text */
    border: none; /* Removes border */
    border-radius: 5px; /* Rounded corners */
    margin-top: 20px; /* Adds some space above the button */
}

.home-button:hover {
    background-color: #444; /* Darker gray on hover */
    cursor: pointer; /* Changes cursor to pointer on hover */
}

    </style>
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": "ScholarlyArticle",
      "@id": "https://doi.org/10.1109/IS264627.2025.11284659",
      "name": "Sounding Canvas: An Embedded, Networked, Interactive Audio Artwork",
      "author": [
        {
          "@type": "Organization",
          "name": "Perceptrum²",
          "sameAs": [
        "https://www.wikidata.org/wiki/Q136547945",
        "https://www.instagram.com/perceptrumduo/",
        "https://www.youtube.com/@perceptrumduo"
      ],
          "url": "https://www.perceptrum.net/"
        },
        {
          "@type": "Person",
          "name": "Luciano Ciamarone",
          "url": "https://luciamarock.github.io/"
        }
      ],
      "datePublished": "2025",
      "publicationVenue": {
        "@type": "ConferenceEvent",
        "name": "IEEE 6th International Symposium on the Internet of Sounds (IS2)",
        "location": "L'Aquila, Italy"
      },
      "url": "https://drive.google.com/file/d/1dK_0AS2yKRtYSKYHG1xg10V1MzUDhyaz/view?usp=sharing",
      "sameAs": "https://www.wikidata.org/wiki/Q137426267",
      "description": "The 'Sounding Canvas' is an interactive art installation transforming a traditional canvas into a dynamic, sound-producing interface, using capacitive sensors, machine learning, and networked interaction."
    },
    {
      "@type": "ScholarlyArticle",
      "@id": "https://doi.org/10.1007/978-3-030-70210-6_11",
      "name": "Automatic Dastgah Recognition Using Markov Models",
      "author": {
        "@type": "Person",
        "name": "Luciano Ciamarone"
      },
      "datePublished": "2019",
      "publicationVenue": {
        "@type": "Book",
        "name": "Perception, Representations, Image, Sound, Music",
        "isbn": "978-3-030-70210-6"
      },
      "url": "https://drive.google.com/file/d/1YPjFcJAnTe_zOXo3BkBXAXuM7yq2SA-0/view?usp=sharing",
      "description": "Automatic recognition of Dastgahs in monophonic recordings of Iranian music using Markov Models, achieving high accuracy via interval sequence analysis."
    },
    {
      "@type": "ScholarlyArticle",
      "@id": "https://doi.org/10.5281/zenodo.17828203",
      "name": "Towards A Real-Time Implementation Of Analogique B",
      "author": {
        "@type": "Person",
        "name": "Luciano Ciamarone"
      },
      "datePublished": "2012",
      "publicationVenue": {
        "@type": "Book",
        "name": "Iannis Xenakis, la musique électroacoustique",
        "isbn": "9782336387970"
      },
      "url": "https://drive.google.com/file/d/1PzGQBV8d06mKnWHGQkkCw3iGsOZ8AmQX/view?usp=sharing",
      "description": "Real-time digital audio implementation of Xenakis' Analogique B using Max/MSP, rendering Markov chain processes and granular synthesis in real-time."
    },
    {
      "@type": "ScholarlyArticle",
      "@id": "https://doi.org/10.6084/m9.figshare.30903413",
      "name": "Environment like strings",
      "author": {
        "@type": "Person",
        "name": "Luciano Ciamarone"
      },
      "datePublished": "2013",
      "publicationVenue": {
        "@type": "Book",
        "name": "Musique et écologies du son - Propositions théoriques pour une écoute du monde",
        "isbn": "9782140010897"
      },
      "url": "https://drive.google.com/file/d/1x0qeM3pKJiHCCKJ2CvCbJWmF4Toto-ze/view?usp=sharing",
      "description": "Algorithmic system for the augmented instrument FeedGuitar, accounting for musical performance history and gesture, for interactive sound ecology research."
    }
  ]
}
</script>

</head>
<body>
<h2> Sounding Canvas: An Embedded, Networked, Interactive Audio Artwork</h2>
<p>2025 IEEE 6th International Symposium on the Internet of Sounds (IS2) - L'Aquila, Italy</p>
<p>The "Sounding Canvas" is an interactive art installation that transforms a traditional canvas into a dynamic, sound-producing interface. Users interact by touching different areas of the canvas, triggering a variety of sounds that appear to emanate directly from the artwork. This experience is facilitated by an embedded system comprising of capacitive sensors connected to an Arduino, a Raspberry Pi 4 for processing and sound generation logic, and a HiFi Berry Amplifier for audio output. The system employs a machine learning decisional algorithm in Python, ensuring that touch interactions result in evolving and varied auditory responses. Furthermore, each canvas can connect to a remote server, allowing multiple installations to share "touch events" in real-time, creating the potential for networked, participatory experiences. This paper details the architecture, implementation, and interactive qualities of the Sounding Canvas, highlighting its relevance as a responsive sound installation and a platform for sonifying touch-based sensor data. </p>
<p><a href="https://drive.google.com/file/d/1dK_0AS2yKRtYSKYHG1xg10V1MzUDhyaz/view?usp=sharing" target="_blank">Download the paper</a></p>
<p>DOI: <a href="https://doi.org/10.1109/IS264627.2025.11284659" target="_blank">10.1109/IS264627.2025.11284659</a></p>

<h2> Automatic Dastgah Recognition Using Markov Models</h2>
<p>CMMR 2019 | Marseille</p>
<p>This work focuses on automatic Dastgah recognition of monophonic audio recordings of Iranian music using Markov Models. We present an automatic recognition system that models the sequence of intervals computed from quantized pitch data (estimated from audio) with Markov processes. Classification of an audio file is performed by finding the closest match between the Markov matrix of the file and the (template) matrices computed from the database for each Dastgah. Applying a leave-one-out evaluation strategy on a dataset comprised of 73 files, an accuracy of 0.986 has been observed for one of the four tested distance calculation methods.</p>
<p>Published in <a href="https://link.springer.com/book/10.1007/978-3-030-70210-6" target="_blank">Perception, Representations, Image, Sound, Music</a> ISBN: 978-3-030-70210-6</p>
<p><a href="https://drive.google.com/file/d/1YPjFcJAnTe_zOXo3BkBXAXuM7yq2SA-0/view" target="_blank">Download the paper</a></p>
<p>DOI: <a href="https://doi.org/10.1007/978-3-030-70210-6_11" target="_blank">10.1007/978-3-030-70210-6_11</a></p>

<h2>Towards A Real-Time Implementation Of Analogique B</h2>
<p>Proceedings of the international Symposium Xenakis. La musique électroacoustique / Xenakis. The electroacoustic music (université Paris 8, May 2012).</p>
<p>This paper details a real-time digital audio implementation of Xenakis's Analogique B. Drawing on his descriptions and prior analysis of his compositional "mechanism" and GRM studio practices in 1958, my implementation in Max-Msp comprises two key programming tasks: (1) rendering the Markov chain process and (2) a real-time granular synthesis engine driven by it. This dual structure reflects the inherent challenge in granular synthesis: representing both grain event sequences and the control structure needed for extensive data management at the grain level. The discussion of my implementation addresses technical issues and proposes future developments to overcome the inherent predictability of Xenakis's closed, memoryless stochastic process.</p>
<p>Published in <a href="https://www.youscribe.com/catalogue/ebooks/art-musique-et-cinema/musique/iannis-xenakis-la-musique-electroacoustique-2629553" target="_blank">Iannis Xenakis, la musique électroacoustique</a> ISBN:9782336387970, 2336387972</p>
<p><a href="https://drive.google.com/file/d/1PzGQBV8d06mKnWHGQkkCw3iGsOZ8AmQX/view" target="_blank">Download the paper</a></p>
<p><a href="https://drive.google.com/file/d/1lpmwLmlveYOHW-aVWdQYG9YaDmKsEXTF/view" target="_blank">Audio Example</a></p>
<p>DOI: <a href="https://doi.org/10.5281/zenodo.17828203" target="_blank">10.5281/zenodo.17828203</a></p>

<h2>Environment like strings</h2>
<p>International Symposium - musique et ècologie du son (université Paris 8, May 2013)</p>
<p>a sophisticated algorithm for my augmented instrument called FeedGuitar that take into account the history of the musical performance signal and the performer's gestures</p>
<p>Published in <a href="https://www.editions-harmattan.fr/catalogue/livre/musique-et-ecologies-du-son/24384?srsltid=AfmBOoocXgUJ2XKovFodHW6woS3aoTwVk6ZgdRPkmqaQs94H0eoCk9E2" target="_blank">Musique et écologies du son - Propositions théoriques pour une écoute du monde</a> ISBN:9782140010897, 2140010892</p>
<p><a href="https://drive.google.com/file/d/1x0qeM3pKJiHCCKJ2CvCbJWmF4Toto-ze/view" target="_blank">Download the poster</a></p>
<p>DOI: <a href="https://doi.org/10.6084/m9.figshare.30903413" target="_blank">10.6084/m9.figshare.30903413</a></p>
<p><a href="https://luciamarock.github.io/" class="home-button">Back to Home</a></p>
</body>
</html>
